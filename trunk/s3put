#!/usr/bin/env python
# Copyright (c) 2006,2007,2008 Mitch Garnaat http://garnaat.org/
#
# Permission is hereby granted, free of charge, to any person obtaining a
# copy of this software and associated documentation files (the
# "Software"), to deal in the Software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish, dis-
# tribute, sublicense, and/or sell copies of the Software, and to permit
# persons to whom the Software is furnished to do so, subject to the fol-
# lowing conditions:
#
# The above copyright notice and this permission notice shall be included
# in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABIL-
# ITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT
# SHALL THE AUTHOR BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, 
# WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
# IN THE SOFTWARE.
#
import getopt, sys, os
import boto
from boto.exception import S3ResponseError

usage_string = """
SYNOPSIS
    s3put [-a access_key] [-s secret_key] -b bucket_name [-d debug_level]
          [-p] [-q] path

    Where
        access_key - Your AWS Access Key ID.  If not supplied, boto will
                     use the value of the environment variable
                     AWS_ACCESS_KEY_ID
        secret_key - Your AWS Secret Access Key.  If not supplied, boto
                     will use the value of the environment variable
                     AWS_SECRET_ACCESS_KEY
        bucket_name - The name of the S3 bucket the file(s) should be
                      copied to.
        path - A path to a directory or file that represents the items
               to be uploaded.  If the path points to an individual file,
               that file will be uploaded to the specified bucket.  If the
               path points to a directory, s3_it will recursively traverse
               the directory and upload all files to the specified bucket.
        debug_level - 0 means no debug output (default), 1 means normal
                      debug output from boto, and 2 means boto debug output
                      plus request/response output from httplib

     If the -p option is provided, a progress callback will be used for
     transfers to S3 and you will see messages printed to the console about
     progress on the upload of individual files.
"""
def usage():
    print usage_string
    sys.exit()
  
def submit_cb(bytes_so_far, total_bytes):
    print '%d bytes transferred / %d bytes total' % (bytes_so_far, total_bytes)

def main():
    try:
        opts, args = getopt.getopt(sys.argv[1:], 'ab:d::hpqs:v',
                                   ['access_key', 'bucket', 'debug', 'help', 'progress', 'quiet', 'secret_key'])
    except:
        usage()
    ignore_dirs = []
    aws_access_key_id = None
    aws_secret_access_key = None
    bucket_name = ''
    total = 0
    debug = 0
    cb = None
    quiet = False
    for o, a in opts:
        if o in ('-h', '--help'):
            usage()
            sys.exit()
        if o in ('-a', '--access_key'):
            aws_access_key_id = a
        if o in ('-b', '--bucket'):
            bucket_name = a
        if o in ('-d', '--debug'):
            debug = int(a)
        if o in ('-p', '--progress'):
            cb = submit_cb
        if o in ('-q', '--quiet'):
            quiet = True
        if o in ('-s', '--secret_key'):
            aws_secret_access_key = a
    if len(args) != 1:
        print usage()
    path = os.path.expanduser(args[0])
    path = os.path.expandvars(path)
    if bucket_name:
        c = boto.connect_s3(aws_access_key_id=aws_access_key_id,
                            aws_secret_access_key=aws_secret_access_key)
        c.debug = debug
        b = c.get_bucket(bucket_name)
        if os.path.isdir(path):
            for root, dirs, files in os.walk(path):
                for ignore in ignore_dirs:
                    if ignore in dirs:
                        dirs.remove(ignore)
                for file in files:
                    fullpath = os.path.join(root, file)
                    if not quiet:
                        print 'Copying %s to %s' % (file, bucket_name)
                    k = b.new_key(file)
                    k.set_contents_from_filename(fullpath, cb=cb)
                    total += 1
        elif os.path.isfile(path):
            k = b.new_key(os.path.split(path)[1])
            k.set_contents_from_filename(path)
    else:
        print usage()

if __name__ == "__main__":
    main()
        
